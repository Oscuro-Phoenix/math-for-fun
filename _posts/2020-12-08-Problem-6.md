---
layout: post
title: Problem 6
subtitle: Conditional Distribution for Gaussians
tags: [Probability]
---
# Problem 6 : Condtional Distribution for Multivariate Gaussians

I started getting interested about the possibilities opened up by incorporating Bayesian models into the machine learning. My room mate during the Globalink Internship program was working on Generative Adversarial Networks (GANs) which often makes use of the math along these lines. The interested me couldn't wait to jump into the topic of Gaussian Process Regression (GPR). I got caught off guard by a theorem that directly gave the condition distribution from a join Gaussian distribution over multiple variables.
<center><img style=" display: block; margin-left: auto; margin-right: auto;width: 30%;" src="../assets/prob5_fig1.jpeg"></center>

# Problem Statement

Let us say that $$ \boldsymbol{Y} $$ is a vector of random variables such that  $$ \boldsymbol{Y} \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma) $$ and we partition $$ \boldsymbol{Y} $$ into
$$ \boldsymbol{y1} $$ and $$ \boldsymbol{y2} $$. Then, $$ \boldsymbol{y1} $$, $$ \boldsymbol{y2} $$ the mean vector and the variance matrix are given by:

$$
\begin{array}{l}
\boldsymbol{\mu}=\left[\begin{array}{l}
\boldsymbol{\mu}_{1} \\
\boldsymbol{\mu}_{2}
\end{array}\right] \\
\boldsymbol{Y}=\left[\begin{array}{l}
\boldsymbol{y}_{1} \\
\boldsymbol{y}_{2}
\end{array}\right]
\end{array}
$$

$$
\left[\begin{array}{ll}
\Sigma_{11} & \Sigma_{12} \\
\Sigma_{21} & \Sigma_{22}
\end{array}\right]
$$

The theorem says that the conditional distribution $$
P(\left(\boldsymbol{y}_{1} \mid \boldsymbol{y}_{2}=\boldsymbol{a}\right))
$$ has the mean vector and covariance matrix given below :

$$
\begin{array}{c}
\overline{\boldsymbol{\mu}}=\boldsymbol{\mu}_{1}+\Sigma_{12} \Sigma_{22}^{-1}\left(\boldsymbol{a}-\boldsymbol{\mu}_{2}\right) \\
\bar{\Sigma}=\Sigma_{11}-\Sigma_{12} \Sigma_{22}{ }^{-1} \Sigma_{21}
\end{array}
$$

# The Solution
